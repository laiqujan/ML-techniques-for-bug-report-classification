{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1496067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "import sklearn\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import gensim\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score\n",
    "from sklearn.metrics import roc_curve,auc,roc_auc_score, make_scorer\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score, precision_score\n",
    "import time\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a3e8d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data - description and title files\n",
    "IR_titles = pd.read_csv('Herzig dataset/title.csv')\n",
    "IR_desc = pd.read_csv('Herzig dataset/desc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "367f6788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    there coupl place your catch interruptedioexce...\n",
       "1    the execut method ha follow simplifi flow 1 ge...\n",
       "Name: the httpstate class ha clearcooki method not synchron but should consid modifi arraylist which unsynchron all other method which modifi read arraylist synchron except clearcooki method I stumbl upon fact becaus webapp I am work use httpclient threw illegalargumentexcept indic one cooki array return methodnam null which shouldnt possibl upon further inspect and test onli possibl option threadsafeti hole left unsynchron clearcooki method caus issu, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IR_desc.iloc[:, 2].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "491f23a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.DataFrame()\n",
    "traindf['labels'] = IR_desc.iloc[:, 1] #labels: 1: Bug and 0; Other\n",
    "traindf['Summary'] = IR_titles.iloc[:, 2]+\" \"+IR_desc.iloc[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3d2b1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>catch sockettimeoutexcept not interruptedioexc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>except dure writerequest leav connect unreleas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>incorrect debug messag httpmethodbas methodnam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>host request header doe not contain port the h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>httpclient fail reconnect after keepal connect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>http client give sme messag proxyhttp endpoint...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>there no way specifi differ auth scheme priori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>httpclient per default relentlessli spam stder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>implement ignorecooki cookiespec It would use ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>javadoc getconnect method connect manag the ja...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                            Summary\n",
       "0       1  catch sockettimeoutexcept not interruptedioexc...\n",
       "1       1  except dure writerequest leav connect unreleas...\n",
       "2       0  incorrect debug messag httpmethodbas methodnam...\n",
       "3       1  host request header doe not contain port the h...\n",
       "4       1  httpclient fail reconnect after keepal connect...\n",
       "5       0  http client give sme messag proxyhttp endpoint...\n",
       "6       0  there no way specifi differ auth scheme priori...\n",
       "7       0  httpclient per default relentlessli spam stder...\n",
       "8       0  implement ignorecooki cookiespec It would use ...\n",
       "9       0  javadoc getconnect method connect manag the ja..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3a56003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5590, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the shape of the data\n",
    "traindf.shape #,testdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f8078b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to clean data\n",
    "def preprocess(text):  \n",
    "    text = str(text)\n",
    "    \n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove non_alphanum\n",
    "    #text = gensim.parsing.preprocessing.strip_non_alphanum(text)\n",
    "    \n",
    "    # remove html tags\n",
    "    #text = gensim.parsing.preprocessing.strip_tags(text)\n",
    "  \n",
    "    # remove punctuation\n",
    "    text = gensim.parsing.preprocessing.strip_punctuation(text)\n",
    "  \n",
    "    # remove numerics\n",
    "    #text = gensim.parsing.preprocessing.strip_numeric(text)\n",
    "  \n",
    "    # remove consecutive whitespace characters and convert tabs to spaces\n",
    "    text = gensim.parsing.preprocessing.strip_multiple_whitespaces(text)\n",
    "  \n",
    "    #text = gensim.parsing.preprocessing.strip_short(text, minsize=3)\n",
    "  \n",
    "    #remove stop-words\n",
    "    text = gensim.parsing.preprocessing.remove_stopwords(text)\n",
    "    \n",
    "    # make stems\n",
    "    text = gensim.parsing.preprocessing.stem_text(text)\n",
    "    \n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "706896dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean training data\n",
    "for index, row in traindf.iterrows():\n",
    "    text = row['Summary']\n",
    "    text = preprocess(text)\n",
    "    traindf.at[index, 'Summary'] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c056539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>catch sockettimeoutexcept interruptedioexcept ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dure writerequest leav connect unrelea execut ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                            Summary\n",
       "0       1  catch sockettimeoutexcept interruptedioexcept ...\n",
       "1       1  dure writerequest leav connect unrelea execut ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e53bf95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get actual labels of training data\n",
    "y = traindf['labels'].values\n",
    "\n",
    "# get summary of training data\n",
    "X = traindf['Summary']\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, norm='l2', encoding='latin-1', ngram_range=(1, 2),\n",
    "                                   stop_words='english')\n",
    "\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f609f9cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1bfec3-9ff9-4bed-8398-fc907b3d3f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timer to check girdsearch time\n",
    "start_time = time.time()\n",
    "# Define the parameter grid for grid search for SGD classifier\n",
    "sgd_param_grid = {\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'max_iter': [1000, 2000],\n",
    "    'loss': ['hinge', 'log']\n",
    "}\n",
    "\n",
    "sgdclassifier = SGDClassifier()\n",
    "sgd_grid_search = GridSearchCV(sgdclassifier, sgd_param_grid,  cv=10, n_jobs=-1)\n",
    "sgd_grid_search.fit(X_tfidf, y)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", sgd_grid_search.best_params_)\n",
    "print(\"Best Score:\", sgd_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf8c0de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1434e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start time for training\n",
    "start_time = time.time()\n",
    "\n",
    "# Define the algorithms to be evaluated\n",
    "algorithms = {\n",
    "    #'Logistic Regression (LR)': LogisticRegression(C = 100, penalty = 'l1', solver= 'saga')\n",
    "    #'Naive Bayes (NB)': MultinomialNB(alpha= 0.1)\n",
    "    #'Support Vector Machine (SVM)': SVC(C=10, gamma= 'scale', kernel= 'linear')\n",
    "    #'K-Nearest Neighbors (KNN)': KNeighborsClassifier(n_neighbors= 7, p= 2, weights= 'distance')\n",
    "    #'Random Forest (RF)': RandomForestClassifier(max_depth = None, min_samples_split = 5, n_estimators = 100),\n",
    "    #'Decision Tree (DT)': DecisionTreeClassifier(max_depth = 20, min_samples_split = 5) #,\n",
    "    'SGDClassifier (hinge)': SGDClassifier(alpha= 0.0001, loss= 'hinge', max_iter= 2000, penalty= 'l2')\n",
    "}\n",
    "\n",
    "# Define performance metric functions\n",
    "performance_metrics = {\n",
    "    'Accuracy': accuracy_score,\n",
    "    'Recall': recall_score,\n",
    "    'Precision': precision_score,\n",
    "    'F1': f1_score,\n",
    "    'MCC': matthews_corrcoef,\n",
    "    'AUC': roc_auc_score\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9eec3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "815da7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: SGDClassifier (hinge)\n",
      "Training time: 2.064100503921509\n",
      "accuracy: 0.8334525939177102\n",
      "auc: 0.801352602490657\n",
      "mcc: 0.6246041589615816\n",
      "nMCC: 0.8123020794807908\n",
      "bug_recall_scores: 0.6962537444946225\n",
      "bug_precision_scores: 0.798373450142631\n",
      "bug_f1_scores: 0.7432364603825572\n",
      "nonbug_recall_scores: 0.9064514604866915\n",
      "nonbug_precision_scores: 0.8490729329326572\n",
      "nonbug_f1_scores: 0.8766707332842276\n"
     ]
    }
   ],
   "source": [
    "# Perform 10-fold cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "for algorithm_name, algorithm in algorithms.items():\n",
    "    print(f\"Algorithm: {algorithm_name}\")\n",
    "    \n",
    "    bug_recall_scores = []\n",
    "    bug_precision_scores = []\n",
    "    bug_f1_scores = []\n",
    "\n",
    "    nonbug_recall_scores = []\n",
    "    nonbug_precision_scores = []\n",
    "    nonbug_f1_scores = []\n",
    "\n",
    "    accuracy_scores = []\n",
    "    auc_scores = []\n",
    "    mcc_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_tfidf):\n",
    "        X_train, X_test = X_tfidf[train_index], X_tfidf[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        algorithm.fit(X_train, y_train)\n",
    "        #print training time\n",
    "        #print(\"Training time:\", time.time() - start_time)\n",
    "        y_pred = algorithm.predict(X_test)\n",
    "\n",
    "        bug_recall_scores.append(recall_score(y_test, y_pred, pos_label=1))\n",
    "        bug_precision_scores.append(precision_score(y_test, y_pred, pos_label=1))\n",
    "        bug_f1_scores.append(f1_score(y_test, y_pred, pos_label=1))\n",
    "\n",
    "        nonbug_recall_scores.append(recall_score(y_test, y_pred, pos_label=0))\n",
    "        nonbug_precision_scores.append(precision_score(y_test, y_pred, pos_label=0))\n",
    "        nonbug_f1_scores.append(f1_score(y_test, y_pred, pos_label=0))\n",
    "\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        auc_scores.append(roc_auc_score(y_test, y_pred))\n",
    "        mcc_scores.append(matthews_corrcoef(y_test, y_pred))\n",
    "\n",
    "    #Compute average scores\n",
    "    # print training time\n",
    "    print(\"Training time:\", time.time() - start_time)\n",
    "    print('accuracy:', mean(accuracy_scores))\n",
    "    print('auc:', mean(auc_scores))\n",
    "    print('mcc:', mean(mcc_scores))\n",
    "    print('nMCC:', ((1+mean(mcc_scores))/2))\n",
    "\n",
    "    print('bug_recall_scores:', mean(bug_recall_scores))\n",
    "    print('bug_precision_scores:', mean(bug_precision_scores))\n",
    "    print('bug_f1_scores:', mean(bug_f1_scores))\n",
    "\n",
    "    print('nonbug_recall_scores:', mean(nonbug_recall_scores))\n",
    "    print('nonbug_precision_scores:', mean(nonbug_precision_scores))\n",
    "    print('nonbug_f1_scores:', mean(nonbug_f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4a154cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208.85546875\n"
     ]
    }
   ],
   "source": [
    "pid = psutil.Process().pid\n",
    "memory_usage_in_bytes = psutil.Process(pid).memory_info().rss\n",
    "memory_usage_in_megabytes = memory_usage_in_bytes / 1024**2\n",
    "\n",
    "print(memory_usage_in_megabytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e8945e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58c9589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grids for grid search for each classifier\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [1, 3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "dt_param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV instances for each classifier\n",
    "knn_grid_search = GridSearchCV(KNeighborsClassifier(), knn_param_grid, cv=5, n_jobs=-1)\n",
    "rf_grid_search = GridSearchCV(RandomForestClassifier(), rf_param_grid, cv=5, n_jobs=-1)\n",
    "dt_grid_search = GridSearchCV(DecisionTreeClassifier(), dt_param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the grid searches to the data for each classifier\n",
    "knn_grid_search.fit(X_tfidf, y)\n",
    "rf_grid_search.fit(X_tfidf, y)\n",
    "dt_grid_search.fit(X_tfidf, y)\n",
    "\n",
    "# Print the best parameters and best scores for each classifier\n",
    "print(\"KNeighborsClassifier Best Parameters:\", knn_grid_search.best_params_)\n",
    "print(\"KNeighborsClassifier Best Score:\", knn_grid_search.best_score_)\n",
    "\n",
    "print(\"RandomForestClassifier Best Parameters:\", rf_grid_search.best_params_)\n",
    "print(\"RandomForestClassifier Best Score:\", rf_grid_search.best_score_)\n",
    "\n",
    "print(\"DecisionTreeClassifier Best Parameters:\", dt_grid_search.best_params_)\n",
    "print(\"DecisionTreeClassifier Best Score:\", dt_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21530fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f43b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for grid search for SVM\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto'] + [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "svcclassifier = SVC()\n",
    "svm_grid_search = GridSearchCV(svcclassifier, svm_param_grid, cv=5, n_jobs=-1)  # 5-fold cross-validation\n",
    "svm_grid_search.fit(X_tfidf, y)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", svm_grid_search.best_params_)\n",
    "print(\"Best Score:\", svm_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf660983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for grid search for SGD classifier\n",
    "sgd_param_grid = {\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'max_iter': [1000, 2000],\n",
    "    'loss': ['hinge', 'log']\n",
    "}\n",
    "\n",
    "sgdclassifier = SGDClassifier()\n",
    "sgd_grid_search = GridSearchCV(sgdclassifier, sgd_param_grid, cv=5)  # 5-fold cross-validation\n",
    "sgd_grid_search.fit(X_tfidf, y)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", sgd_grid_search.best_params_)\n",
    "print(\"Best Score:\", sgd_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4335ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a pipeline with a CountVectorizer and MultinomialNB\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "#mnb_param_grid = { 'vectorizer__max_features': [1000, 5000, 10000],'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "   # 'classifier__alpha': [0.1, 1, 10]\n",
    "#}\n",
    "\n",
    "mnb_param_grid = { 'classifier__alpha': [0.1, 1, 10] }\n",
    "\n",
    "mnbclf = MultinomialNB()\n",
    "\n",
    "# Create the GridSearchCV instance\n",
    "mnb_grid_search = GridSearchCV(mnbclf, mnb_param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "mnb_grid_search.fit(X_tfidf, y)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", mnb_grid_search.best_params_)\n",
    "print(\"Best Score:\", mnb_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3463e3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best Parameters: {'classifier__alpha': 1, 'vectorizer__max_features': 10000, 'vectorizer__ngram_range': (1, 2)}\n",
    "Best Score: 0.8003577817531304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ab6c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for grid search for LR\n",
    "\n",
    "lr_param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Inverse of regularization strength\n",
    "    'penalty': ['l1', 'l2'],       # Regularization type (L1 or L2)\n",
    "    'solver': ['liblinear', 'saga']  # Solver algorithms for logistic regression\n",
    "}\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000)  # Create a logistic regression classifier\n",
    "\n",
    "lr_grid_search = GridSearchCV(logreg, lr_param_grid, cv=5, n_jobs=-1)  # 5-fold cross-validation\n",
    "lr_grid_search.fit(X_tfidf, y)\n",
    "\n",
    "best_params = lr_grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e38c828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7be30e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e79919e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858181b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bc6acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timer to check training time\n",
    "start_time = time.time()\n",
    "\n",
    "# prediction on test data for evaluation\n",
    "predicted = classifier.predict(X_test)\n",
    "\n",
    "# print testing time\n",
    "print(\"Testing time:\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39af5c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print classification report\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5870140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate micro precision score\n",
    "P = sklearn.metrics.precision_score(y_test, predicted, average='micro')\n",
    "\n",
    "# calculate micro recall score\n",
    "R = sklearn.metrics.recall_score(y_test, predicted, average='micro')\n",
    "\n",
    "# calculate micro f1 score\n",
    "F1 = sklearn.metrics.f1_score(y_test, predicted, average='micro')\n",
    "\n",
    "#print micro scores\n",
    "print(\"=*= micro averages =*=\")\n",
    "print(f\"precision:\\t{P:.4f}\")\n",
    "print(f\"recall:\\t\\t{R:.4f}\")\n",
    "print(f\"F1 score:\\t{F1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dfdc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267ba65a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
